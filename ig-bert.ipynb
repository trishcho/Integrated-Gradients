{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import bert\n",
    "from bert import tokenization\n",
    "from IPython.display import display\n",
    "from bert_model_utils import transform_input, generate_baseline, \\\n",
    "        get_ig_attributions, visualize_token_attrs, get_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients on BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1112 22:20:32.449114 140007072298816 deprecation.py:323] From <ipython-input-2-a7d64c6e6112>:7: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "W1112 22:20:34.410744 140007072298816 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1282: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Tensorflow Session and load the saved model\n",
    "SESS = tf.Session()\n",
    "\n",
    "\n",
    "# =========================================== MODIFY THIS =============================================\n",
    "# Directory should be in TF Saved Model Directory Format https://www.tensorflow.org/guide/saved_model\n",
    "SAVED_MODEL_PATH = '<PATH TO BERT SAVED MODEL DIRECTORY>'\n",
    "saved_model = tf.saved_model.loader.load(sess=SESS, tags=['serve'], export_dir=SAVED_MODEL_PATH)\n",
    "\n",
    "\n",
    "# Path to Tokenizer in pickle format. \n",
    "# The BertModel directory has a base uncased tokenizer\n",
    "TOKENIZER_PATH = '<PATH TO TOKENIZER>'\n",
    "with open(TOKENIZER_PATH, 'rb') as file:\n",
    "    TOKENIZER = pickle.load(file)\n",
    "# ======================================================================================================    \n",
    "# The embedding tensor of the model. This may change depending on your model, \n",
    "# you may need to grep the operations in the graph.\n",
    "# Please refer to https://github.com/ankurtaly/Integrated-Gradients/blob/master/howto.md\n",
    "# Here we choose the tensor that sums up the three kinds of BERT embeddings. \n",
    "# Please refer to the BERT architecture for more context\n",
    "EMBEDDING_TENSOR = get_tensor(SESS, 'module_apply_tokens/bert/embeddings/add_1:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1112 22:20:36.371488 140007072298816 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible outputs are ['labels', 'probabilities']\n"
     ]
    }
   ],
   "source": [
    "# Define the input tensors using the SignatureDef\n",
    "sig = saved_model.signature_def[\"serving_default\"]\n",
    "INPUT_TENSORS = sig.inputs\n",
    "\n",
    "# Get output tensor for model using the SignatureDef\n",
    "output_keys = list(sig.outputs)\n",
    "print(f'Possible outputs are {output_keys}')\n",
    "# This is instructional, change this if you want to calculate on some \n",
    "# other output. Note that the output should be \n",
    "# a differentiable function of the embedding tensor \n",
    "\n",
    "OUTPUT_TENSOR = get_tensor(SESS, sig.outputs['probabilities'].name)\n",
    "\n",
    "# Gradient tensor of output wrt embedding tensor\n",
    "GRADIENT_TENSOR = tf.gradients(OUTPUT_TENSOR[:, 1], EMBEDDING_TENSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is 1.955999141500797e-05\n",
      "baseline_prediction is 0.4553076922893524\n",
      "delta_prediction is -0.4552881419658661\n",
      "sum_attributions are -0.4555169343948364\n",
      "Error percentage is -0.050252226641011435\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <span style='color:rgb(115,154,115)'>this </span> <span style='color:rgb(136,124,124)'>was </span> <span style='color:rgb(154,115,115)'>an </span> <span style='color:rgb(255,64,64)'>awful </span> <span style='color:rgb(149,117,117)'>movie </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame structure that we will input into the model\n",
    "input_df = pd.DataFrame(columns=['sentence'], data=['This was an awful movie'])\n",
    "\n",
    "# Transform the data into a format acceptable to the model.\n",
    "# You may need to modify the function depending on your model input interface\n",
    "transformed_input_df = transform_input(TOKENIZER, input_df)\n",
    "\n",
    "# Generate a baseline. The baseline we use is a padded sequence of the same length \n",
    "# as the input sentence, to avoid attribution to the start (CLS) and end of sequence (SEP) tokens\n",
    "baseline_df = generate_baseline(TOKENIZER, input_df)\n",
    "\n",
    "\n",
    "ig = get_ig_attributions(sess=SESS, \n",
    "                         input_tensors=INPUT_TENSORS, \n",
    "                         embedding_tensor=EMBEDDING_TENSOR,\n",
    "                         gradient_tensor=GRADIENT_TENSOR, \n",
    "                         output_tensor=OUTPUT_TENSOR, \n",
    "                         transformed_input_df=transformed_input_df,\n",
    "                         baseline_df=baseline_df, \n",
    "                         tokenizer=TOKENIZER, \n",
    "                         debug=True)\n",
    "display(visualize_token_attrs(ig['outputs'][0], np.array(ig['outputs'][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <span style='color:rgb(108,168,108)'>this </span> <span style='color:rgb(102,180,102)'>was </span> <span style='color:rgb(121,142,121)'>a </span> <span style='color:rgb(64,255,64)'>good </span> <span style='color:rgb(160,112,112)'>movie </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style='color:rgb(119,145,119)'>this </span> <span style='color:rgb(127,129,127)'>was </span> <span style='color:rgb(255,64,64)'>not </span> <span style='color:rgb(156,114,114)'>a </span> <span style='color:rgb(106,172,106)'>good </span> <span style='color:rgb(164,110,110)'>movie </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style='color:rgb(113,157,113)'>this </span> <span style='color:rgb(155,114,114)'>was </span> <span style='color:rgb(255,64,64)'>not </span> <span style='color:rgb(110,164,110)'>a </span> <span style='color:rgb(82,220,82)'>great </span> <span style='color:rgb(162,111,111)'>movie </span> <span style='color:rgb(125,133,125)'>, </span> <span style='color:rgb(115,154,115)'>but </span> <span style='color:rgb(105,174,105)'>a </span> <span style='color:rgb(67,250,67)'>good </span> <span style='color:rgb(160,112,112)'>movie </span> <span style='color:rgb(120,144,120)'>nevertheless </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style='color:rgb(100,184,100)'>this </span> <span style='color:rgb(172,106,106)'>was </span> <span style='color:rgb(125,133,125)'>a </span> <span style='color:rgb(255,64,64)'>terrible </span> <span style='color:rgb(180,102,102)'>movie </span> <span style='color:rgb(150,117,117)'>. </span> <span style='color:rgb(151,116,116)'>do </span> <span style='color:rgb(135,124,124)'>you </span> <span style='color:rgb(117,149,117)'>agree </span> <span style='color:rgb(165,109,109)'>? </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through data points\n",
    "sentences = ['This was a good movie', \n",
    "             'This was not a good movie', \n",
    "             'This was not a great movie, but a good movie nevertheless',\n",
    "             'This was a terrible movie. Do you agree?']\n",
    "\n",
    "for sentence in sentences:\n",
    "    input_df['sentence'][0] = sentence\n",
    "    transformed_input_df = transform_input(TOKENIZER, input_df.head(1))\n",
    "    baseline_df = generate_baseline(TOKENIZER, input_df.head(1))\n",
    "    ig = get_ig_attributions(sess=SESS, \n",
    "                             input_tensors=INPUT_TENSORS, \n",
    "                             embedding_tensor=EMBEDDING_TENSOR,\n",
    "                             gradient_tensor=GRADIENT_TENSOR, \n",
    "                             output_tensor=OUTPUT_TENSOR, \n",
    "                             transformed_input_df=transformed_input_df,\n",
    "                             baseline_df=baseline_df, \n",
    "                             tokenizer=TOKENIZER)\n",
    "    display(visualize_token_attrs(ig['outputs'][0], np.array(ig['outputs'][1])))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Predicting Movie Reviews with BERT on TF Hub.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
